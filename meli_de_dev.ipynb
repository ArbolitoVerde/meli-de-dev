{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727d8034-33d8-4e0e-a940-91f3d0aadf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "class DataCreator:\n",
    "\n",
    "    SCHEMA = {\n",
    "        'date': 'datetime64[ns]',\n",
    "        'user_id': 'int32',\n",
    "        'position': 'int32',\n",
    "        'value_prop_print': 'str',\n",
    "        'click_flag': 'int32',\n",
    "        'views_last3_weeks': 'int32',\n",
    "        'clicks_last3_weeks': 'int32',\n",
    "        'pays_last3_weeks': 'int32',\n",
    "        'import_pay_last3_weeks': 'float64'\n",
    "    }\n",
    "\n",
    "    def __init__(self, prints_path: str, taps_path: str, pays_path: str, process_weeks: int) -> None:\n",
    "        self.__prints_path = prints_path\n",
    "        self.__taps_path = taps_path\n",
    "        self.__pays_path = pays_path\n",
    "        self.__process_weeks = process_weeks\n",
    "\n",
    "\n",
    "    def __read_file(self, file_path: str) -> DataFrame:\n",
    "        \"\"\"Hace lectura de los archivos inputs necesarios para calcular el dataset final.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): localización del archivo a leer.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: se transforma el input ya sea json o csv a un dataframe.\n",
    "        \"\"\"\n",
    "\n",
    "        data = []\n",
    "        if file_path.endswith('.json'):\n",
    "            try: \n",
    "                with open(f'{file_path}', 'r') as f:\n",
    "                    for line in f:\n",
    "                        data.append(json.loads(line))\n",
    "                f.close()\n",
    "                df = pd.json_normalize(data)\n",
    "                df.rename(columns = {'day':'date', 'event_data.position':'position', 'event_data.value_prop':'value_prop'}, inplace = True)\n",
    "                return df\n",
    "            except FileNotFoundError as fnf_error:\n",
    "                print(fnf_error)\n",
    "            except:\n",
    "                print(\"Something went wrong\")\n",
    "        elif file_path.endswith('.csv'):\n",
    "            try: \n",
    "                df = pd.read_csv(\"pays.csv\")\n",
    "                df = df.groupby(['pay_date','user_id','value_prop'])['total'].sum()\n",
    "                return df\n",
    "            except FileNotFoundError as fnf_error:\n",
    "                print(fnf_error)\n",
    "            except:\n",
    "                print(\"Something went wrong\")\n",
    "        else:\n",
    "            print(\"Wrong extension file, only reading json or csv files\")\n",
    "\n",
    "\n",
    "    def __validate_key_fields(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"Valida la existencia de duplicidad de la llave de los df de prints y taps, si existen, son eliminados\n",
    "            retornando un dataset sin ellos.\n",
    "\n",
    "        Args:\n",
    "            df (DataFrame): Dataframe a validar.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: Dataframe sin duplicados.\n",
    "        \"\"\"\n",
    "        duplicates = df.groupby(['date', 'user_id', 'position']).filter(lambda x: len(x) > 1).value_counts()\n",
    "        if len(duplicates) > 0:\n",
    "            return df.drop_duplicates(keep='last').reset_index()\n",
    "        else:\n",
    "            return df\n",
    "        \n",
    "\n",
    "    def __create_join_table(self, prints: DataFrame, taps: DataFrame, pays: DataFrame) -> DataFrame:\n",
    "        \"\"\"Genera el join de las tres tablas involucradas en el proceso.\n",
    "\n",
    "        Args:\n",
    "            prints (DataFrame): prints data\n",
    "            taps (DataFrame): taps data\n",
    "            pays (DataFrame): pays data\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: datos cruzados en función del df input prints.\n",
    "        \"\"\"\n",
    "        prints = self.__validate_key_fields(prints)\n",
    "        taps = self.__validate_key_fields(taps)\n",
    "        \n",
    "        prints_taps = pd.merge(prints, taps, on=['date', 'user_id', 'position'], suffixes=('_print', '_tap'), how='left')\n",
    "        joined_data = pd.merge(prints_taps, pays, left_on=['date','user_id','value_prop_print'], right_on=['pay_date','user_id','value_prop'], how='left')\n",
    "        joined_data['click_flag'] = 1\n",
    "        joined_data.loc[joined_data['value_prop_tap'].isnull(), 'click_flag'] = 0\n",
    "        joined_data['date'] = pd.to_datetime(joined_data['date'])\n",
    "        joined_data['year_week_id'] = joined_data['date'].dt.year.astype('int32') * 100 + \\\n",
    "                                        joined_data['date'].dt.isocalendar().week.astype('int32')\n",
    "        joined_data['row_num_week'] = joined_data['year_week_id'].rank(method ='dense',ascending=True).astype('int32')\n",
    "        return joined_data\n",
    "    \n",
    "    \n",
    "    def __create_ouput_dataset(self, df: DataFrame, wk: int) -> DataFrame:\n",
    "        \"\"\"Genera la estructura con los datos solicitados como output\n",
    "\n",
    "        Args:\n",
    "            df (DataFrame): dataset sobre el cual se van a calcular los KPIs\n",
    "            wk (int): cantidad de semanas móviles que se consideraran para calcular los KPIs\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: df con la estructura y datos requeridos como output\n",
    "        \"\"\"\n",
    "        max_week = df['row_num_week'].max() \n",
    "        early_weeks = df.query(f'row_num_week >= {max_week}-{wk} and row_num_week < {max_week}')\n",
    "        agg_early_weeks = early_weeks.groupby(['user_id','value_prop_print']).aggregate({'value_prop_print':'count', 'click_flag':'sum','total':['count','sum']})\n",
    "        agg_early_weeks = pd.DataFrame(agg_early_weeks.to_records())\n",
    "        agg_early_weeks.columns = ['user_id', 'value_prop_print', f'views_last{wk}_weeks', f'clicks_last{wk}_weeks', f'pays_last{wk}_weeks', f'import_pay_last{wk}_weeks']\n",
    "\n",
    "        last_week = df.query(f'row_num_week == {max_week}')\n",
    "        tmp_output = pd.merge(last_week, agg_early_weeks, on=['user_id', 'value_prop_print'], how='left')\n",
    "        output = tmp_output[['date', 'user_id', 'position', 'value_prop_print', 'click_flag', f'views_last{wk}_weeks', f'clicks_last{wk}_weeks', f'pays_last{wk}_weeks', f'import_pay_last{wk}_weeks']].fillna(0)\n",
    "        output = output.astype(self.SCHEMA)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def get_output_dataset(self) -> DataFrame:\n",
    "        \"\"\"Función que gestiona el llamado a los métodos privados para generar output.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: df con la estructura y datos requeridos como output\n",
    "        \"\"\"\n",
    "        prints = self.__read_file(self.__prints_path)\n",
    "        taps = self.__read_file(self.__taps_path)\n",
    "        pays = self.__read_file(self.__pays_path)\n",
    "\n",
    "        join_df = self.__create_join_table(prints, taps, pays)\n",
    "        dataset = self.__create_ouput_dataset(join_df, self.__process_weeks)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6f3684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>position</th>\n",
       "      <th>value_prop_print</th>\n",
       "      <th>click_flag</th>\n",
       "      <th>views_last3_weeks</th>\n",
       "      <th>clicks_last3_weeks</th>\n",
       "      <th>pays_last3_weeks</th>\n",
       "      <th>import_pay_last3_weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>59706</td>\n",
       "      <td>0</td>\n",
       "      <td>send_money</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>32191</td>\n",
       "      <td>0</td>\n",
       "      <td>link_cobro</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>32191</td>\n",
       "      <td>1</td>\n",
       "      <td>transport</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>32191</td>\n",
       "      <td>2</td>\n",
       "      <td>send_money</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>53960</td>\n",
       "      <td>0</td>\n",
       "      <td>prepaid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  user_id  position value_prop_print  click_flag  \\\n",
       "0 2020-11-30    59706         0       send_money           0   \n",
       "1 2020-11-30    32191         0       link_cobro           0   \n",
       "2 2020-11-30    32191         1        transport           0   \n",
       "3 2020-11-30    32191         2       send_money           0   \n",
       "4 2020-11-30    53960         0          prepaid           0   \n",
       "\n",
       "   views_last3_weeks  clicks_last3_weeks  pays_last3_weeks  \\\n",
       "0                  0                   0                 0   \n",
       "1                  1                   0                 0   \n",
       "2                  0                   0                 0   \n",
       "3                  0                   0                 0   \n",
       "4                  0                   0                 0   \n",
       "\n",
       "   import_pay_last3_weeks  \n",
       "0                     0.0  \n",
       "1                     0.0  \n",
       "2                     0.0  \n",
       "3                     0.0  \n",
       "4                     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRINTS_PATH = '/Users/seba/Documents/Data Engineering Development/meli-de-dev/prints.json'\n",
    "TAPS_PATH = '/Users/seba/Documents/Data Engineering Development/meli-de-dev/taps.json'\n",
    "PAYS_PATH = '/Users/seba/Documents/Data Engineering Development/meli-de-dev/pays.csv'\n",
    "PROCESS_WEEKS = 3\n",
    "\n",
    "data_creator = DataCreator(PRINTS_PATH, TAPS_PATH, PAYS_PATH, PROCESS_WEEKS)\n",
    "dataset = data_creator.get_output_dataset()\n",
    "dataset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
